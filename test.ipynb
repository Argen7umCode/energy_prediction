{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from utils.get_sequences import get_sequences\n",
    "from utils.split_data import split_data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from data_files.data_module import EnergyChickenDataModule\n",
    "from model_files.model import LSTM\n",
    "from model_files.trainer import Trainer\n",
    "from torch.optim import Adam, SGD, Adadelta, AdamW, Adagrad\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "SPLITER_COUNT = 0.8\n",
    "WINDOW_LENGHT = 24 # window size of one month\n",
    "BATCH_SIZE = 32\n",
    "MAX_COUNT_DECREASING = 10\n",
    "LEARNING_RATE = 0.001\n",
    "N_EPOCHS = 10\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_files/processed.csv')\n",
    "df.drop(columns=df.columns[0], inplace=True)\n",
    "scaler = StandardScaler()\n",
    "data = torch.FloatTensor(scaler.fit_transform(df.iloc[:, 0].to_numpy().reshape((-1, 1)))).to(DEVICE)[:1000]\n",
    "\n",
    "sequences = get_sequences(data, WINDOW_LENGHT)\n",
    "train, test = split_data(sequences, SPLITER_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(device=DEVICE)\n",
    "optimizers = [Adam, SGD, Adadelta, AdamW, Adagrad] # optimizers that we will test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f8951de2140>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argen7um/Desktop/code/energy_prediction/data_files/dataset.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return (torch.Tensor(sequence), torch.tensor(label).float())\n",
      "/home/argen7um/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 train_loss 0.960212 test_loss 0.798444 time 2.584301\n",
      "epoch 2 train_loss 0.960212 test_loss 0.798444 time 3.004226\n",
      "epoch 3 train_loss 0.960212 test_loss 0.798444 time 2.907451\n",
      "epoch 4 train_loss 0.960212 test_loss 0.798444 time 2.97694\n",
      "epoch 5 train_loss 0.960212 test_loss 0.798444 time 2.878132\n",
      "epoch 6 train_loss 0.960212 test_loss 0.798444 time 2.831639\n",
      "epoch 7 train_loss 0.960212 test_loss 0.798444 time 2.684386\n",
      "epoch 8 train_loss 0.960212 test_loss 0.798444 time 2.79569\n",
      "epoch 9 train_loss 0.960212 test_loss 0.798444 time 2.430878\n",
      "epoch 10 train_loss 0.960212 test_loss 0.798444 time 2.59186\n",
      "SGD\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f8951a05420>\n",
      "epoch 1 train_loss 0.995324 test_loss 0.920691 time 2.999958\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/argen7um/Desktop/code/energy_prediction/test.ipynb Ячейка 5\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/argen7um/Desktop/code/energy_prediction/test.ipynb#X12sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mprint\u001b[39m(train_dataloader)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/argen7um/Desktop/code/energy_prediction/test.ipynb#X12sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m trainer\u001b[39m.\u001b[39mupload_data(train_dataloader, test_dataloader)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/argen7um/Desktop/code/energy_prediction/test.ipynb#X12sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mfit()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/argen7um/Desktop/code/energy_prediction/test.ipynb#X12sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m comparison_logs[optimizer_name] \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39mlogs\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/argen7um/Desktop/code/energy_prediction/test.ipynb#X12sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mcompatison_results.json\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m file:\n",
      "File \u001b[0;32m~/Desktop/code/energy_prediction/model_files/trainer.py:107\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, log)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_epochs):\n\u001b[1;32m    106\u001b[0m     start_time \u001b[39m=\u001b[39m time()\n\u001b[0;32m--> 107\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmake_epoch() \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mstop\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    108\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    109\u001b[0m     time_delta \u001b[39m=\u001b[39m time() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/Desktop/code/energy_prediction/model_files/trainer.py:77\u001b[0m, in \u001b[0;36mTrainer.make_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39meval()\n\u001b[1;32m     76\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> 77\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__make_mileage_according_data(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_dataset, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     79\u001b[0m mean_epoch_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogs[\u001b[39m'\u001b[39m\u001b[39mtest_loss\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m     80\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol_loss(mean_epoch_loss) \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mstop\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/code/energy_prediction/model_files/trainer.py:45\u001b[0m, in \u001b[0;36mTrainer.__make_mileage_according_data\u001b[0;34m(self, data, is_train)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__make_mileage_according_data\u001b[39m(\u001b[39mself\u001b[39m, data, is_train\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     44\u001b[0m     epoch_loss \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 45\u001b[0m     \u001b[39mfor\u001b[39;00m sequence, labels \u001b[39min\u001b[39;00m data:\n\u001b[1;32m     46\u001b[0m         sequence \u001b[39m=\u001b[39m sequence\u001b[39m.\u001b[39mview((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[1;32m     47\u001b[0m         labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mview((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:61\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 61\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    205\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[39m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[39m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     \u001b[39mreturn\u001b[39;00m collate(batch, collate_fn_map\u001b[39m=\u001b[39;49mdefault_collate_fn_map)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:143\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    140\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m--> 143\u001b[0m     \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:143\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    140\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m--> 143\u001b[0m     \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:120\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39mif\u001b[39;00m collate_fn_map \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[39mif\u001b[39;00m elem_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 120\u001b[0m         \u001b[39mreturn\u001b[39;00m collate_fn_map[elem_type](batch, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map)\n\u001b[1;32m    122\u001b[0m     \u001b[39mfor\u001b[39;00m collate_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    123\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:163\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    161\u001b[0m     storage \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mstorage()\u001b[39m.\u001b[39m_new_shared(numel, device\u001b[39m=\u001b[39melem\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    162\u001b[0m     out \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mnew(storage)\u001b[39m.\u001b[39mresize_(\u001b[39mlen\u001b[39m(batch), \u001b[39m*\u001b[39m\u001b[39mlist\u001b[39m(elem\u001b[39m.\u001b[39msize()))\n\u001b[0;32m--> 163\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mstack(batch, \u001b[39m0\u001b[39;49m, out\u001b[39m=\u001b[39;49mout)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "comparison_logs = {}\n",
    "\n",
    "for optimizer in optimizers:\n",
    "    data_module = EnergyChickenDataModule(train, test)\n",
    "    data_module.setup()\n",
    "    train_dataloader = data_module.train_dataloader()\n",
    "    test_dataloader = data_module.test_dataloader()\n",
    "\n",
    "    optimizer_name = str(optimizer).split('.')[-1][:-2]\n",
    "    optimizer = optimizer(model.parameters(), lr=LEARNING_RATE)\n",
    "    print(optimizer_name)\n",
    "\n",
    "    model = LSTM(device=DEVICE)\n",
    "    trainer = Trainer(model=model, \n",
    "                optimizer=optimizer, \n",
    "                loss_function=criterion,\n",
    "                n_epochs=N_EPOCHS,\n",
    "                device=DEVICE,\n",
    "                max_count_decreasing=MAX_COUNT_DECREASING)\n",
    "    print(train_dataloader)\n",
    "\n",
    "    trainer.upload_data(train_dataloader, test_dataloader)\n",
    "    trainer.fit()\n",
    "    \n",
    "    comparison_logs[optimizer_name] = trainer.logs\n",
    "    with open('compatison_results.json', 'w') as file:\n",
    "        json.dump(comparison_logs, file, ensure_ascii=False, indent=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adam\n",
    "epoch 1 train_loss 0.95369 test_loss 0.894374 time 3.842928\n",
    "epoch 2 train_loss 0.95369 test_loss 0.894374 time 3.861985"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stat = trainer.logs\n",
    "train_loss = stat['train_loss']\n",
    "test_loss = stat['test_loss']\n",
    "min_train_loss = min(train_loss)\n",
    "min_train_loss_epoch = train_loss.index(min_train_loss)\n",
    "min_test_loss = min(test_loss)\n",
    "min_test_loss_epoch = test_loss.index(min_test_loss)\n",
    "print(f'train_loss {(1-min_train_loss**0.5)*100}\\ntest_loss {(1-min_test_loss**0.5)*100} ')\n",
    "\n",
    "plt.scatter([min_train_loss_epoch], [min_train_loss], label='Min train loss')\n",
    "plt.scatter([min_test_loss_epoch], [min_test_loss], label='Min test loss')\n",
    "plt.plot(train_loss, label='Train loss')\n",
    "plt.plot(test_loss, label='Test loss')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdamW\n"
     ]
    }
   ],
   "source": [
    "print(str(AdamW).split('.')[-1][:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
